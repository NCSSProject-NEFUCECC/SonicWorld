<template>
  <div id="root" ref="refRoot" class="accompanying-mode">
    <div class="header">
      <h2>é™ªä¼´æ¨¡å¼</h2>
      <p>ä½¿ç”¨å½•éŸ³ä¸AIåŠ©æ‰‹è¿›è¡Œå¯¹è¯</p>
    </div>
    
    <div class="content">
      <!-- å½•éŸ³æ§åˆ¶ç»„ä»¶ -->
      <div class="voice-recorder">
        <div class="recorder-controls">
          <button 
            @click="toggleListening"
            :disabled="isConnecting"
            :class="{ 
              'active': isListening,
              'connecting': isConnecting,
              'recording': isRecording
            }"
            class="chat-button"
          >
            <span v-if="isConnecting">å‡†å¤‡ä¸­...</span>
            <span v-else-if="isRecording">ğŸ¤ å½•éŸ³ä¸­</span>
            <span v-else-if="isListening">ğŸ‘‚ èŠå¤©ä¸­</span>
            <span v-else>ğŸ¤ å¼€å§‹èŠå¤©</span>
          </button>
        </div>
        
        <div v-if="currentStatus" class="status-display">
          <span class="status-text">{{ currentStatus }}</span>
        </div>
        
        <div v-if="audioLevel > 0" class="audio-level">
          <div class="level-bar">
            <div 
              class="level-fill" 
              :style="{ width: audioLevel + '%' }"
            ></div>
          </div>
          <span class="level-text">éŸ³é‡: {{ Math.round(audioLevel) }}%</span>
        </div>
      </div>
      
      <!-- å¯¹è¯å†å² -->
      <div v-if="conversations.length > 0" class="conversation-history">
        <h3>å¯¹è¯è®°å½•</h3>
        <div class="messages">
          <div 
            v-for="(msg, index) in conversations" 
            :key="index"
            :class="['message', msg.type]"
          >
            <div class="message-content">
              <strong>{{ msg.type === 'user' ? 'ç”¨æˆ·' : 'AIåŠ©æ‰‹' }}ï¼š</strong>
              {{ msg.content }}
            </div>
            <div class="message-time">{{ formatTime(msg.timestamp) }}</div>
          </div>
        </div>
      </div>
      

    </div>
  </div>
</template>

<script setup lang="ts">
import { ref, onMounted, onUnmounted } from 'vue'
import { chat } from '@/services/AIService'
import type { Message } from '@/datasource/types'

interface Conversation {
  type: 'user' | 'assistant'
  content: string
  timestamp: Date
}



// çŠ¶æ€ç®¡ç†
const conversations = ref<Conversation[]>([])
const currentStatus = ref('')
const isProcessing = ref(false)
const isRecording = ref(false)
const isConnecting = ref(false)
const isListening = ref(false)
const audioLevel = ref(0)

// åª’ä½“ç›¸å…³
let mediaRecorder: MediaRecorder | null = null
let audioStream: MediaStream | null = null
let audioContext: AudioContext | null = null
let analyser: AnalyserNode | null = null
let dataArray: Uint8Array | null = null
let animationFrame: number | null = null
let recordingStartTime: number = 0
let silenceTimeout: number | null = null
let isCurrentlyRecording = false

// éŸ³é¢‘ç›‘å¬é˜ˆå€¼
const SILENCE_THRESHOLD = 30 // é™éŸ³é˜ˆå€¼
const VOICE_THRESHOLD = 50 // è¯´è¯é˜ˆå€¼
const SILENCE_DURATION = 2000 // é™éŸ³æŒç»­æ—¶é—´(ms)ååœæ­¢å½•éŸ³
const MIN_RECORDING_DURATION = 1000 // æœ€å°å½•éŸ³æ—¶é•¿(ms)

// è·å–éº¦å…‹é£æƒé™å¹¶åˆå§‹åŒ–éŸ³é¢‘ä¸Šä¸‹æ–‡
const initializeAudio = async (): Promise<void> => {
  try {
    audioStream = await navigator.mediaDevices.getUserMedia({
      audio: {
        sampleRate: 44100,
        channelCount: 1,
        echoCancellation: true,
        noiseSuppression: true
      }
    })
    
    audioContext = new AudioContext()
    analyser = audioContext.createAnalyser()
    const source = audioContext.createMediaStreamSource(audioStream)
    source.connect(analyser)
    
    analyser.fftSize = 256
    const bufferLength = analyser.frequencyBinCount
    dataArray = new Uint8Array(bufferLength)
    
    console.log('éŸ³é¢‘åˆå§‹åŒ–æˆåŠŸ')
  } catch (error) {
    console.error('è·å–éº¦å…‹é£æƒé™å¤±è´¥:', error)
    currentStatus.value = 'æ— æ³•è®¿é—®éº¦å…‹é£ï¼Œè¯·æ£€æŸ¥æƒé™è®¾ç½®'
    throw error
  }
}

// è®¡ç®—éŸ³é¢‘éŸ³é‡
const getAudioLevel = (): number => {
  if (!analyser || !dataArray) return 0
  
  analyser.getByteFrequencyData(dataArray)
  let sum = 0
  for (let i = 0; i < dataArray.length; i++) {
    sum += dataArray[i]
  }
  const average = sum / dataArray.length
  return (average / 255) * 100
}

// ç›‘å¬éŸ³é¢‘éŸ³é‡å˜åŒ–
const monitorAudioLevel = () => {
  if (!isListening.value && !isRecording.value) return
  
  const level = getAudioLevel()
  audioLevel.value = level
  
  // å¦‚æœæ­£åœ¨ç›‘å¬æ¨¡å¼ä¸”æ£€æµ‹åˆ°è¯´è¯
  if (isListening.value && !isCurrentlyRecording && level > VOICE_THRESHOLD) {
    console.log('æ£€æµ‹åˆ°è¯´è¯ï¼Œå¼€å§‹å½•éŸ³')
    startRecordingFromListening()
  }
  
  // å¦‚æœæ­£åœ¨å½•éŸ³ä¸”æ£€æµ‹åˆ°é™éŸ³
  if (isCurrentlyRecording && level < SILENCE_THRESHOLD) {
    if (!silenceTimeout) {
      silenceTimeout = setTimeout(() => {
        console.log('æ£€æµ‹åˆ°é™éŸ³ï¼Œåœæ­¢å½•éŸ³')
        stopRecording()
      }, SILENCE_DURATION)
    }
  } else if (silenceTimeout) {
    clearTimeout(silenceTimeout)
    silenceTimeout = null
  }
  
  animationFrame = requestAnimationFrame(monitorAudioLevel)
}

// å‘é€å½•éŸ³åˆ°è¯­éŸ³è½¬æ–‡å­—API
const sendRecordingToSTT = async (audioBlob: Blob): Promise<string> => {
  try {
    const formData = new FormData()
    formData.append('audio', audioBlob, 'recording.webm')
    
    const response = await fetch('/api/cpny', {
      method: 'POST',
      body: formData
    })
    
    if (!response.ok) {
      throw new Error(`è¯­éŸ³è½¬æ–‡å­—å¤±è´¥: ${response.statusText}`)
    }
    
    const result = await response.json()
    return result.text || ''
  } catch (error) {
    console.error('è¯­éŸ³è½¬æ–‡å­—å¤±è´¥:', error)
    throw error
  }
}

// å¼€å§‹å½•éŸ³
const startRecording = async () => {
  if (!audioStream) return
  
  try {
    mediaRecorder = new MediaRecorder(audioStream, {
      mimeType: 'audio/webm;codecs=opus'
    })
    
    const chunks: Blob[] = []
    
    mediaRecorder.ondataavailable = (event) => {
      if (event.data.size > 0) {
        chunks.push(event.data)
      }
    }
    
    mediaRecorder.onstop = async () => {
      const blob = new Blob(chunks, { type: 'audio/webm' })
      const duration = Date.now() - recordingStartTime
      
      // åªå¤„ç†è¶…è¿‡æœ€å°æ—¶é•¿çš„å½•éŸ³
      if (duration >= MIN_RECORDING_DURATION) {
        try {
          currentStatus.value = 'æ­£åœ¨è½¬æ¢è¯­éŸ³...'
          
          // å‘é€åˆ°è¯­éŸ³è½¬æ–‡å­—API
          const transcribedText = await sendRecordingToSTT(blob)
          
          if (transcribedText.trim()) {
            // æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å¯¹è¯å†å²
            conversations.value.push({
              type: 'user',
              content: transcribedText,
              timestamp: new Date()
            })
            
            // å‘é€ç»™AIå¤„ç†
            await sendToAI(transcribedText)
          } else {
            currentStatus.value = 'æœªè¯†åˆ«åˆ°è¯­éŸ³å†…å®¹'
            setTimeout(() => {
              currentStatus.value = ''
            }, 2000)
          }
        } catch (error) {
          console.error('å¤„ç†å½•éŸ³å¤±è´¥:', error)
          currentStatus.value = 'è¯­éŸ³å¤„ç†å¤±è´¥ï¼Œè¯·é‡è¯•'
          setTimeout(() => {
            currentStatus.value = ''
          }, 3000)
        }
      } else {
        currentStatus.value = 'å½•éŸ³æ—¶é—´å¤ªçŸ­ï¼Œå·²ä¸¢å¼ƒ'
        setTimeout(() => {
          currentStatus.value = ''
        }, 2000)
      }
    }
    
    recordingStartTime = Date.now()
    mediaRecorder.start()
    isRecording.value = true
    isCurrentlyRecording = true
    currentStatus.value = 'æ­£åœ¨å½•éŸ³...'
    
    // å¼€å§‹ç›‘å¬éŸ³é¢‘
    monitorAudioLevel()
    
  } catch (error) {
    console.error('å½•éŸ³å¤±è´¥:', error)
    currentStatus.value = 'å½•éŸ³å¤±è´¥'
  }
}

// ä»ç›‘å¬æ¨¡å¼å¼€å§‹å½•éŸ³
const startRecordingFromListening = async () => {
  if (isCurrentlyRecording) return
  
  // åœæ­¢å½“å‰AIè¾“å‡ºï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
  if (isProcessing.value) {
    // è¿™é‡Œå¯ä»¥æ·»åŠ åœæ­¢AIè¾“å‡ºçš„é€»è¾‘
    console.log('æ£€æµ‹åˆ°ç”¨æˆ·è¯´è¯ï¼Œä¸­æ–­AIè¾“å‡º')
  }
  
  await startRecording()
}

// åœæ­¢å½•éŸ³
const stopRecording = () => {
  if (mediaRecorder && mediaRecorder.state === 'recording') {
    mediaRecorder.stop()
  }
  
  isRecording.value = false
  isCurrentlyRecording = false
  
  if (silenceTimeout) {
    clearTimeout(silenceTimeout)
    silenceTimeout = null
  }
  
  if (animationFrame) {
    cancelAnimationFrame(animationFrame)
    animationFrame = null
  }
  
  audioLevel.value = 0
}

// å¼€å§‹/åœæ­¢ç›‘å¬
const toggleListening = async () => {
  if (isListening.value) {
    stopListening()
  } else {
    await startListening()
  }
}

// å¼€å§‹ç›‘å¬
const startListening = async () => {
  try {
    if (!audioStream) {
      await initializeAudio()
    }
    
    isListening.value = true
    currentStatus.value = 'æ­£åœ¨ç›‘å¬éº¦å…‹é£...'
    monitorAudioLevel()
    
  } catch (error) {
    console.error('å¯åŠ¨ç›‘å¬å¤±è´¥:', error)
    currentStatus.value = 'å¯åŠ¨ç›‘å¬å¤±è´¥'
  }
}

// åœæ­¢ç›‘å¬
const stopListening = () => {
  isListening.value = false
  
  if (animationFrame) {
    cancelAnimationFrame(animationFrame)
    animationFrame = null
  }
  
  audioLevel.value = 0
  currentStatus.value = ''
}



// å‘é€æ¶ˆæ¯åˆ°AIæœåŠ¡
const sendToAI = async (userMessage: string) => {
  if (isProcessing.value) return
  
  try {
    isProcessing.value = true
    currentStatus.value = 'æ­£åœ¨æ€è€ƒ...'
    
    // æ„å»ºæ¶ˆæ¯å†å²
    const messages: Message[] = conversations.value.map(conv => ({
      role: conv.type === 'user' ? 'user' : 'assistant',
      content: conv.content
    }))
    
    // æ·»åŠ å½“å‰ç”¨æˆ·æ¶ˆæ¯ï¼ˆå¦‚æœè¿˜æ²¡æ·»åŠ ï¼‰
    const lastMessage = messages[messages.length - 1]
    if (!lastMessage || lastMessage.content !== userMessage) {
      messages.push({
        role: 'user',
        content: userMessage
      })
    }
    
    // è°ƒç”¨AIæœåŠ¡
    let aiResponse = ''
    await chat(messages, (chunk: string) => {
      aiResponse += chunk
      // å®æ—¶æ›´æ–°AIå›å¤ï¼ˆå¯é€‰ï¼‰
      currentStatus.value = `AIå›å¤ä¸­: ${aiResponse.substring(0, 50)}...`
    })
    
    // æ·»åŠ AIå›å¤åˆ°å¯¹è¯å†å²
    conversations.value.push({
      type: 'assistant',
      content: aiResponse,
      timestamp: new Date()
    })
    
    currentStatus.value = 'AIå›å¤å®Œæˆ'
    
    // æ¸…é™¤çŠ¶æ€
    setTimeout(() => {
      currentStatus.value = ''
    }, 2000)
    
  } catch (error) {
    console.error('AIæœåŠ¡è°ƒç”¨å¤±è´¥:', error)
    currentStatus.value = 'AIæœåŠ¡è°ƒç”¨å¤±è´¥ï¼Œè¯·é‡è¯•'
    
    setTimeout(() => {
      currentStatus.value = ''
    }, 3000)
  } finally {
    isProcessing.value = false
  }
}

// æ ¼å¼åŒ–æ—¶é—´
const formatTime = (date: Date): string => {
  return date.toLocaleTimeString('zh-CN', {
    hour: '2-digit',
    minute: '2-digit',
    second: '2-digit'
  })
}

// æ ¼å¼åŒ–æ—¶é•¿
const formatDuration = (duration: number): string => {
  const seconds = Math.floor(duration / 1000)
  const minutes = Math.floor(seconds / 60)
  const remainingSeconds = seconds % 60
  
  if (minutes > 0) {
    return `${minutes}:${remainingSeconds.toString().padStart(2, '0')}`
  }
  return `${remainingSeconds}ç§’`
}

// æ¸…ç†èµ„æº
const cleanup = () => {
  stopRecording()
  stopListening()
  
  if (audioStream) {
    audioStream.getTracks().forEach(track => track.stop())
    audioStream = null
  }
  
  if (audioContext) {
    audioContext.close()
    audioContext = null
  }
}

// ç»„ä»¶æŒ‚è½½æ—¶åˆå§‹åŒ–
onMounted(() => {
  console.log('é™ªä¼´æ¨¡å¼ç»„ä»¶å·²æŒ‚è½½')
})

// ç»„ä»¶å¸è½½æ—¶æ¸…ç†
onUnmounted(() => {
  cleanup()
})
</script>

<style scoped>
.accompanying-mode {
  padding: 20px;
  max-width: 800px;
  margin: 0 auto;
  background: #f8f9fa;
  min-height: 100vh;
}

.header {
  text-align: center;
  margin-bottom: 30px;
  padding: 20px;
  background: white;
  border-radius: 12px;
  box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
}

.header h2 {
  margin: 0 0 10px 0;
  color: #333;
  font-size: 28px;
}

.header p {
  margin: 0;
  color: #666;
  font-size: 16px;
}

.content {
  display: flex;
  flex-direction: column;
  gap: 20px;
}

.conversation-history {
  background: white;
  border-radius: 12px;
  padding: 20px;
  box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
}

.conversation-history h3 {
  margin: 0 0 15px 0;
  color: #333;
  font-size: 20px;
}

.messages {
  max-height: 400px;
  overflow-y: auto;
  display: flex;
  flex-direction: column;
  gap: 12px;
}

.message {
  padding: 12px 16px;
  border-radius: 8px;
  max-width: 80%;
}

.message.user {
  background: #007bff;
  color: white;
  align-self: flex-end;
  margin-left: auto;
}

.message.assistant {
  background: #e9ecef;
  color: #333;
  align-self: flex-start;
}

.message-content {
  margin-bottom: 4px;
  line-height: 1.4;
  white-space: pre-wrap;
  word-wrap: break-word;
}

.message-time {
  font-size: 12px;
  opacity: 0.7;
}

.status-display {
  background: #fff3cd;
  border: 1px solid #ffeaa7;
  border-radius: 8px;
  padding: 12px 16px;
  text-align: center;
}

.status-text {
  color: #856404;
  font-weight: 500;
}

.config-error {
  background: #f8d7da;
  border: 1px solid #f5c6cb;
  border-radius: 12px;
  padding: 20px;
  margin-bottom: 20px;
  color: #721c24;
}

.config-error h3 {
  margin: 0 0 15px 0;
  color: #721c24;
  font-size: 18px;
}

.config-error ul {
  margin: 10px 0;
  padding-left: 20px;
}

.config-error li {
  margin: 5px 0;
}

.config-help {
  margin-top: 15px;
  padding: 15px;
  background: rgba(255, 255, 255, 0.5);
  border-radius: 8px;
}

.config-help ol {
  margin: 10px 0;
  padding-left: 20px;
}

.config-help li {
  margin: 8px 0;
  line-height: 1.4;
}

.config-help a {
  color: #0056b3;
  text-decoration: none;
}

.config-help a:hover {
  text-decoration: underline;
}

.config-help code {
  background: #e9ecef;
  padding: 2px 6px;
  border-radius: 4px;
  font-family: 'Courier New', monospace;
  font-size: 14px;
}

.test-tool-section {
  margin-top: 20px;
  padding: 15px;
  background: rgba(255, 255, 255, 0.7);
  border-radius: 8px;
  border: 1px solid #dee2e6;
}

.toggle-test-button,
.quick-test-button {
  background: #17a2b8;
  color: white;
  border: none;
  padding: 10px 20px;
  border-radius: 6px;
  cursor: pointer;
  font-size: 14px;
  font-weight: 500;
  transition: background-color 0.2s;
  margin-top: 10px;
}

.toggle-test-button:hover,
.quick-test-button:hover {
  background: #138496;
}

.test-tool-container {
  margin-top: 20px;
  padding: 20px;
  background: #f8f9fa;
  border-radius: 8px;
  border: 1px solid #dee2e6;
}

.quick-test {
  margin-top: 20px;
  padding: 15px;
  background: #e9ecef;
  border-radius: 8px;
  text-align: center;
}

.voice-recorder {
  background: white;
  border-radius: 12px;
  padding: 20px;
  box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
  margin-bottom: 20px;
}

.recorder-controls {
  display: flex;
  gap: 15px;
  margin-bottom: 15px;
  flex-wrap: wrap;
}

.chat-button {
  padding: 12px 24px;
  border: none;
  border-radius: 8px;
  background: #007bff;
  color: white;
  cursor: pointer;
  font-size: 16px;
  font-weight: 500;
  transition: all 0.3s ease;
  min-width: 120px;
}

.chat-button:hover:not(:disabled) {
  background: #0056b3;
  transform: translateY(-1px);
}

.chat-button:disabled {
  opacity: 0.6;
  cursor: not-allowed;
}

.chat-button.recording {
  background: #dc3545;
  animation: pulse 1.5s infinite;
}

.chat-button.connecting {
  background: #ffc107;
  color: #000;
}

.chat-button.active {
  background: #28a745;
  animation: listening-pulse 2s infinite;
}

.audio-level {
  margin-top: 15px;
}

.level-bar {
  width: 100%;
  height: 8px;
  background: #e9ecef;
  border-radius: 4px;
  overflow: hidden;
  margin-bottom: 8px;
}

.level-fill {
  height: 100%;
  background: linear-gradient(90deg, #28a745, #ffc107, #dc3545);
  transition: width 0.1s ease;
  border-radius: 4px;
}

.level-text {
  font-size: 14px;
  color: #666;
  font-weight: 500;
}



@keyframes pulse {
  0% {
    transform: scale(1);
    box-shadow: 0 0 0 0 rgba(220, 53, 69, 0.7);
  }
  50% {
    transform: scale(1.05);
    box-shadow: 0 0 0 10px rgba(220, 53, 69, 0);
  }
  100% {
    transform: scale(1);
    box-shadow: 0 0 0 0 rgba(220, 53, 69, 0);
  }
}

@keyframes listening-pulse {
  0% {
    box-shadow: 0 0 0 0 rgba(40, 167, 69, 0.7);
  }
  50% {
    box-shadow: 0 0 0 10px rgba(40, 167, 69, 0);
  }
  100% {
    box-shadow: 0 0 0 0 rgba(40, 167, 69, 0);
  }
}

/* å“åº”å¼è®¾è®¡ */
@media (max-width: 768px) {
  .accompanying-mode {
    padding: 15px;
  }
  
  .header {
    padding: 15px;
  }
  
  .header h2 {
    font-size: 24px;
  }
  
  .message {
    max-width: 90%;
  }
  
  .recorder-controls {
    flex-direction: column;
    align-items: stretch;
  }
  
  .chat-button {
    width: 100%;
  }
}

/* æ»šåŠ¨æ¡æ ·å¼ */
.messages::-webkit-scrollbar {
  width: 6px;
}

.messages::-webkit-scrollbar-track {
  background: #f1f1f1;
  border-radius: 3px;
}

.messages::-webkit-scrollbar-thumb {
  background: #c1c1c1;
  border-radius: 3px;
}

.messages::-webkit-scrollbar-thumb:hover {
  background: #a8a8a8;
}
</style>