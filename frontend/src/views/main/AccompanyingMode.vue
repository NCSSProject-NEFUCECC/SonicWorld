<template>
  <div class="accompanying-mode">
    <div class="header">
      <h2>é™ªä¼´æ¨¡å¼</h2>
      <p>ä½¿ç”¨è¯­éŸ³ä¸AIåŠ©æ‰‹è¿›è¡Œå¯¹è¯</p>
    </div>
    
    <div class="content">
      <!-- å½•éŸ³æ§åˆ¶ç»„ä»¶ -->
      <div class="voice-recorder">
        <div class="recorder-controls">
          <button 
            @click="toggleListening"
            :disabled="isConnecting"
            :class="{ 
              'active': isListening,
              'connecting': isConnecting,
              'recording': isRecording
            }"
            class="chat-button"
          >
            <span v-if="isConnecting">å‡†å¤‡ä¸­...</span>
            <span v-else-if="isRecording">ğŸ¤ å½•éŸ³ä¸­</span>
            <span v-else-if="isListening">ğŸ‘‚ èŠå¤©ä¸­</span>
            <span v-else>ğŸ¤ å¼€å§‹èŠå¤©</span>
          </button>
        </div>
        
        <div v-if="currentStatus" class="status-display">
          <span class="status-text">{{ currentStatus }}</span>
        </div>
        
        <div v-if="audioLevel > 0" class="audio-level">
          <div class="level-bar">
            <div 
              class="level-fill" 
              :style="{ width: audioLevel + '%' }"
            ></div>
          </div>
          <span class="level-text">éŸ³é‡: {{ Math.round(audioLevel) }}%</span>
        </div>
      </div>
      
      <!-- å¯¹è¯å†å² -->
      <div v-if="conversations.length > 0" class="conversation-history">
        <h3>å¯¹è¯è®°å½•</h3>
        <div class="messages">
          <div 
            v-for="(msg, index) in conversations" 
            :key="index"
            :class="['message', msg.type]"
          >
            <div class="message-content">
              <strong>{{ msg.type === 'user' ? 'ç”¨æˆ·' : 'AIåŠ©æ‰‹' }}ï¼š</strong>
              {{ msg.content }}
            </div>
            <div class="message-time">{{ formatTime(msg.timestamp) }}</div>
          </div>
        </div>
      </div>
      

    </div>
  </div>
</template>

<script setup lang="ts">
import { ref, onMounted, onUnmounted } from 'vue'
import { chat } from '@/services/AIService'
import type { Message } from '@/datasource/types'

interface Conversation {
  type: 'user' | 'assistant'
  content: string
  timestamp: Date
}



// çŠ¶æ€ç®¡ç†
const conversations = ref<Conversation[]>([])
const currentStatus = ref('')
const isProcessing = ref(false)
const isRecording = ref(false)
const isConnecting = ref(false)
const isListening = ref(false)
const audioLevel = ref(0)

// åª’ä½“ç›¸å…³
let mediaRecorder: MediaRecorder | null = null
let audioStream: MediaStream | null = null
let analyser: AnalyserNode | null = null
let dataArray: Uint8Array | null = null
let animationFrame: number | null = null
let recordingStartTime: number = 0
let silenceTimeout: number | null = null
let isCurrentlyRecording = false

// éŸ³é¢‘ç›‘å¬é˜ˆå€¼
const SILENCE_THRESHOLD = 3 // é™éŸ³é˜ˆå€¼ - å½“éŸ³é‡å°äº3%æ—¶è®¤ä¸ºç”¨æˆ·å·²ç»è¯´å®Œè¯
const VOICE_THRESHOLD = 10 // è¯´è¯é˜ˆå€¼ - å½“éŸ³é‡å¤§äº10%æ—¶å¼€å§‹å½•éŸ³
const SILENCE_DURATION = 500 // é™éŸ³æŒç»­æ—¶é—´(ms)ååœæ­¢å½•éŸ³ - 0.5ç§’
const MIN_RECORDING_DURATION = 100 // æœ€å°å½•éŸ³æ—¶é•¿(ms) - é™ä½æœ€å°æ—¶é•¿ä»¥é€‚åº”æ›´æ•æ„Ÿçš„æ£€æµ‹

// è·å–éº¦å…‹é£æƒé™å¹¶åˆå§‹åŒ–éŸ³é¢‘ä¸Šä¸‹æ–‡
const initializeAudio = async (): Promise<void> => {
  try {
    console.log('å¼€å§‹è¯·æ±‚éº¦å…‹é£æƒé™...')
    audioStream = await navigator.mediaDevices.getUserMedia({
      audio: {
        sampleRate: 44100,
        channelCount: 1,
        echoCancellation: true,
        noiseSuppression: true
      }
    })
    console.log('éº¦å…‹é£æƒé™è·å–æˆåŠŸï¼ŒéŸ³é¢‘æµå·²åˆ›å»º')
    
    audioContext.value = new AudioContext()
    analyser = audioContext.value.createAnalyser()
    const source = audioContext.value.createMediaStreamSource(audioStream)
    source.connect(analyser)
    
    analyser.fftSize = 256
    const bufferLength = analyser.frequencyBinCount
    dataArray = new Uint8Array(bufferLength)
    
    console.log('éŸ³é¢‘åˆå§‹åŒ–æˆåŠŸï¼Œåˆ†æå™¨å·²è®¾ç½®ï¼Œç¼“å†²åŒºé•¿åº¦:', bufferLength)
    
    // æµ‹è¯•éŸ³é¢‘æ•°æ®è·å–
    const testLevel = getAudioLevel()
    console.log('åˆå§‹éŸ³é¢‘æµ‹è¯•ï¼Œå½“å‰éŸ³é‡:', testLevel.toFixed(1), '%')
    
  } catch (error) {
    console.error('è·å–éº¦å…‹é£æƒé™å¤±è´¥:', error)
    currentStatus.value = 'æ— æ³•è®¿é—®éº¦å…‹é£ï¼Œè¯·æ£€æŸ¥æƒé™è®¾ç½®'
    throw error
  }
}

// è®¡ç®—éŸ³é¢‘éŸ³é‡
const getAudioLevel = (): number => {
  if (!analyser || !dataArray) return 0
  
  // ä½¿ç”¨æ—¶åŸŸæ•°æ®æ¥è®¡ç®—éŸ³é‡ï¼Œæ›´å‡†ç¡®åœ°åæ˜ å®é™…éŸ³é‡
  analyser.getByteTimeDomainData(dataArray)
  let sum = 0
  for (let i = 0; i < dataArray.length; i++) {
    // è®¡ç®—ä¸ä¸­å¿ƒå€¼(128)çš„åå·®
    const deviation = Math.abs(dataArray[i] - 128)
    sum += deviation
  }
  const average = sum / dataArray.length
  // å°†åå·®è½¬æ¢ä¸ºç™¾åˆ†æ¯” (æœ€å¤§åå·®ä¸º127)
  return ((average / 127) * 100)+1
}

// ç›‘å¬éŸ³é¢‘éŸ³é‡å˜åŒ–
const monitorAudioLevel = () => {
  if (!isListening.value && !isRecording.value) {
    console.log('éŸ³é¢‘ç›‘æ§åœæ­¢ï¼šisListening=', isListening.value, 'isRecording=', isRecording.value)
    return
  }
  
  const level = getAudioLevel()
  audioLevel.value = level
  
  // æ¯éš”ä¸€æ®µæ—¶é—´è¾“å‡ºéŸ³é‡ä¿¡æ¯ï¼ˆé¿å…è¿‡å¤šæ—¥å¿—ï¼‰
  // if (Math.random() < 0.05) { // çº¦5%çš„æ¦‚ç‡è¾“å‡ºï¼Œå¢åŠ é¢‘ç‡ä»¥ä¾¿éªŒè¯ä¿®å¤
  //   console.log(`[éŸ³é‡è°ƒè¯•] è®¡ç®—éŸ³é‡: ${level.toFixed(1)}%, å‰ç«¯æ˜¾ç¤º: ${audioLevel.value.toFixed(1)}%, ç›‘å¬: ${isListening.value}, å½•éŸ³: ${isCurrentlyRecording}`)
  // }
  
  // å¦‚æœæ­£åœ¨ç›‘å¬æ¨¡å¼ä¸”æ£€æµ‹åˆ°è¯´è¯
  if (isListening.value && !isCurrentlyRecording && level > VOICE_THRESHOLD) {
    console.log(`æ£€æµ‹åˆ°è¯´è¯ (${level.toFixed(1)}% > ${VOICE_THRESHOLD}%)ï¼Œå¼€å§‹å½•éŸ³`)
    startRecordingFromListening()
  }
  
  // å¦‚æœæ­£åœ¨å½•éŸ³ä¸”æ£€æµ‹åˆ°é™éŸ³
  if (isCurrentlyRecording && level < SILENCE_THRESHOLD) {
    if (!silenceTimeout) {
      console.log(`æ£€æµ‹åˆ°é™éŸ³ (${level.toFixed(1)}% < ${SILENCE_THRESHOLD}%)ï¼Œå¼€å§‹é™éŸ³è®¡æ—¶å™¨`)
      silenceTimeout = setTimeout(() => {
        console.log('é™éŸ³æŒç»­2ç§’ï¼Œåœæ­¢å½•éŸ³å¹¶å‘é€åˆ°åç«¯')
        stopRecording()
      }, SILENCE_DURATION)
    }
  } else if (isCurrentlyRecording && silenceTimeout) {
    // æ­£åœ¨å½•éŸ³ä¸”éŸ³é‡é‡æ–°è¶…è¿‡é™éŸ³é˜ˆå€¼ï¼Œæ¸…é™¤é™éŸ³å®šæ—¶å™¨
    console.log(`éŸ³é‡æ¢å¤ (${level.toFixed(1)}% >= ${SILENCE_THRESHOLD}%)ï¼Œæ¸…é™¤é™éŸ³è®¡æ—¶å™¨`)
    clearTimeout(silenceTimeout)
    silenceTimeout = null
  }
  
  animationFrame = requestAnimationFrame(monitorAudioLevel)
}

// å‘é€å½•éŸ³åˆ°é™ªä¼´æ¨¡å¼APIå¹¶å¤„ç†æµå¼å“åº”
const sendRecordingToCompanion = async (audioBlob: Blob): Promise<void> => {
  try {
    console.log(`[å‰ç«¯] å‡†å¤‡å‘é€å½•éŸ³æ•°æ®ï¼Œå¤§å°: ${audioBlob.size} å­—èŠ‚ï¼Œç±»å‹: ${audioBlob.type}`)
    const formData = new FormData()
    formData.append('audio', audioBlob, 'recording.webm')
    
    console.log('[å‰ç«¯] å¼€å§‹å‘é€è¯·æ±‚åˆ° /api/cpny')
    const response = await fetch('/api/cpny', {
      method: 'POST',
      body: formData
    })
    
    console.log(`[å‰ç«¯] æ”¶åˆ°å“åº”ï¼ŒçŠ¶æ€ç : ${response.status}, çŠ¶æ€æ–‡æœ¬: ${response.statusText}`)
    
    if (!response.ok) {
      throw new Error(`é™ªä¼´æ¨¡å¼è¯·æ±‚å¤±è´¥: ${response.statusText}`)
    }
    
    // å¤„ç†æµå¼å“åº”
    const reader = response.body?.getReader()
    if (!reader) {
      throw new Error('æ— æ³•è¯»å–å“åº”æµ')
    }
    
    const decoder = new TextDecoder()
    let aiResponse = ''
    let userText = ''
    let hasAddedUserMessage = false
    
    while (true) {
      const { done, value } = await reader.read()
      if (done) break
      
      const chunk = decoder.decode(value, { stream: true })
      const lines = chunk.split('\n')
      
      for (const line of lines) {
        if (line.startsWith('data: ')) {
          const data = line.slice(6)
          
          if (data === '[å®Œæˆ]') {
            // AIå›å¤å®Œæˆ
            if (aiResponse.trim()) {
              conversations.value.push({
                type: 'assistant',
                content: aiResponse,
                timestamp: new Date()
              })
            }
            currentStatus.value = 'AIå›å¤å®Œæˆ'
            setTimeout(() => {
              currentStatus.value = ''
            }, 2000)
            return
          } else if (data.startsWith('audio,')) {
            // å¤„ç†éŸ³é¢‘æ•°æ®
            const audioHex = data.slice(6)
            console.log('æ¥æ”¶åˆ°éŸ³é¢‘æ•°æ®ï¼ŒåŸå§‹é•¿åº¦:', data.length, 'åå…­è¿›åˆ¶é•¿åº¦:', audioHex.length)
            console.log('éŸ³é¢‘æ•°æ®å‰100å­—ç¬¦:', audioHex.substring(0, 100))
            try {
              playAudioFromHex(audioHex)
            } catch (audioError) {
              console.error('éŸ³é¢‘æ’­æ”¾å¤±è´¥:', audioError)
            }
          } else if (data.startsWith('STT:')) {
            // å¤„ç†STTè¯†åˆ«ç»“æœ
            userText = data.slice(4).trim()
            if (userText && !hasAddedUserMessage) {
              conversations.value.push({
                type: 'user',
                content: userText,
                timestamp: new Date()
              })
              hasAddedUserMessage = true
              currentStatus.value = 'è¯­éŸ³è¯†åˆ«å®Œæˆï¼ŒAIæ€è€ƒä¸­...'
            }
          } else if (data.trim() && !data.startsWith('STT:')) {
            // å¤„ç†AIå›å¤æ–‡æœ¬æ•°æ®
            aiResponse += data
            currentStatus.value = `AIå›å¤ä¸­: ${aiResponse.substring(0, 50)}...`
          }
        }
      }
    }
    
  } catch (error: unknown) {
    const err = error as Error
    console.error('[å‰ç«¯] é™ªä¼´æ¨¡å¼è¯·æ±‚å¤±è´¥:', err)
    console.error('[å‰ç«¯] é”™è¯¯è¯¦æƒ…:', {
      message: err.message,
      stack: err.stack,
      name: err.name
    })
    throw err
  }
}

// éŸ³é¢‘ç›¸å…³çŠ¶æ€
const audioContext = ref<AudioContext | null>(null)
const audioQueue = ref<Uint8Array[]>([])
const isPlayingAudio = ref(false)
const activeAudioSource = ref<AudioBufferSourceNode | null>(null)

// åˆå§‹åŒ–éŸ³é¢‘ä¸Šä¸‹æ–‡
const initAudioContext = () => {
  if (!audioContext.value) {
    audioContext.value = new (window.AudioContext || (window as any).webkitAudioContext)()
    console.log('AudioContext initialized, state:', audioContext.value.state)
  }
}

// WAVç¼–ç å™¨ - å¤„ç†16ä½PCMæ•°æ®
const encodeWav = (pcmData: Uint8Array, sampleRate: number): ArrayBuffer => {
  const numChannels = 1
  const bytesPerSample = 2
  const dataSize = pcmData.length
  const buffer = new ArrayBuffer(44 + dataSize)
  const view = new DataView(buffer)

  console.log('ç¼–ç WAV - PCMæ•°æ®é•¿åº¦:', dataSize, 'å­—èŠ‚')
  console.log('ç¼–ç WAV - é¢„æœŸéŸ³é¢‘æ—¶é•¿:', (dataSize / (sampleRate * bytesPerSample)).toFixed(2), 'ç§’')

  // RIFFå¤´éƒ¨
  writeString(view, 0, 'RIFF')
  view.setUint32(4, 36 + dataSize, true)
  writeString(view, 8, 'WAVE')

  // fmtå­å—
  writeString(view, 12, 'fmt ')
  view.setUint32(16, 16, true)
  view.setUint16(20, 1, true) // PCMæ ¼å¼
  view.setUint16(22, numChannels, true)
  view.setUint32(24, sampleRate, true)
  view.setUint32(28, sampleRate * numChannels * bytesPerSample, true)
  view.setUint16(32, numChannels * bytesPerSample, true)
  view.setUint16(34, 16, true) // 16ä½æ·±åº¦

  // dataå­å—
  writeString(view, 36, 'data')
  view.setUint32(40, dataSize, true)

  // å¡«å……PCMæ•°æ®
  new Uint8Array(buffer).set(pcmData, 44)
  
  return buffer
}

// å†™å…¥å­—ç¬¦ä¸²åˆ°DataView
const writeString = (view: DataView, offset: number, str: string) => {
  for (let i = 0; i < str.length; i++) {
    view.setUint8(offset + i, str.charCodeAt(i))
  }
}

// æ’­æ”¾éŸ³é¢‘å‡½æ•°
const playAudio = (audioData: Uint8Array): Promise<void> => {
  return new Promise((resolve) => {
    if (!audioContext.value) {
      console.error('AudioContext not initialized')
      return resolve()
    }

    console.log('å¼€å§‹æ’­æ”¾éŸ³é¢‘ï¼Œæ•°æ®é•¿åº¦:', audioData.length)
    
    // ç¡®ä¿AudioContextå¤„äºè¿è¡ŒçŠ¶æ€
    if (audioContext.value.state === 'suspended') {
      audioContext.value.resume().then(() => {
        playAudioInternal(audioData, resolve)
      }).catch((error: any) => {
        console.error('Error resuming AudioContext:', error)
        resolve()
      })
    } else {
      playAudioInternal(audioData, resolve)
    }
  })
}

// å†…éƒ¨éŸ³é¢‘æ’­æ”¾å‡½æ•°
const playAudioInternal = (audioData: Uint8Array, resolve: () => void) => {
  try {
    const wavBuffer = encodeWav(audioData, 24000)
    console.log('WAV buffer created, size:', wavBuffer.byteLength)
    
    audioContext.value!.decodeAudioData(wavBuffer).then(audioBuffer => {
      console.log('éŸ³é¢‘è§£ç æˆåŠŸï¼Œæ—¶é•¿:', audioBuffer.duration, 'ç§’')
      
      const source = audioContext.value!.createBufferSource()
      const gainNode = audioContext.value!.createGain()
      
      activeAudioSource.value = source
      source.buffer = audioBuffer
      
      // è®¾ç½®éŸ³é‡
      gainNode.gain.value = 1.0
      console.log('éŸ³é‡è®¾ç½®ä¸º:', 1.0)
      
      // è¿æ¥éŸ³é¢‘èŠ‚ç‚¹
      source.connect(gainNode)
      gainNode.connect(audioContext.value!.destination)
      
      // æ’­æ”¾ç»“æŸå¤„ç†
      source.onended = () => {
        console.log('éŸ³é¢‘æ’­æ”¾ç»“æŸ')
        isPlayingAudio.value = false
        activeAudioSource.value = null
        resolve()
        // ç»§ç»­å¤„ç†é˜Ÿåˆ—ä¸­çš„ä¸‹ä¸€ä¸ªéŸ³é¢‘
        setTimeout(() => {
          processAudioQueue()
        }, 100)
      }
      
      // å¼€å§‹æ’­æ”¾
      isPlayingAudio.value = true
      source.start(0)
      console.log('éŸ³é¢‘å¼€å§‹æ’­æ”¾')
      
    }).catch((error: any) => {
      console.error('Error decoding audio:', error)
      isPlayingAudio.value = false
      resolve()
    })
    
  } catch (error) {
    console.error('æ’­æ”¾éŸ³é¢‘æ—¶å‡ºé”™:', error)
    isPlayingAudio.value = false
    resolve()
  }
}

// å¤„ç†éŸ³é¢‘é˜Ÿåˆ—
const processAudioQueue = async () => {
  if (isPlayingAudio.value) {
    console.log('éŸ³é¢‘æ­£åœ¨æ’­æ”¾ä¸­ï¼Œç­‰å¾…é˜Ÿåˆ—å¤„ç†')
    return
  }
  if (audioQueue.value.length === 0) {
    console.log('éŸ³é¢‘é˜Ÿåˆ—ä¸ºç©º')
    return
  }
  
  console.log('å¼€å§‹å¤„ç†éŸ³é¢‘é˜Ÿåˆ—ï¼Œé˜Ÿåˆ—é•¿åº¦:', audioQueue.value.length)
  const nextAudio = audioQueue.value.shift()!
  await playAudio(nextAudio)
}

// æ’­æ”¾åå…­è¿›åˆ¶éŸ³é¢‘æ•°æ®
const playAudioFromHex = (audioHex: string): void => {
  try {
    console.log('æ”¶åˆ°éŸ³é¢‘æ•°æ®ï¼Œé•¿åº¦:', audioHex.length)
    console.log('éŸ³é¢‘æ•°æ®æ ·æœ¬:', audioHex.substring(0, 50))
    
    // ç¡®ä¿AudioContextå·²åˆå§‹åŒ–
    initAudioContext()
    
    // å°†åå…­è¿›åˆ¶å­—ç¬¦ä¸²è½¬æ¢ä¸ºå­—èŠ‚æ•°ç»„
    const audioData = new Uint8Array(
      audioHex.match(/.{1,2}/g)?.map((byte: string) => parseInt(byte, 16)) || []
    )
    
    if (audioData.length > 0) {
      console.log('éŸ³é¢‘æ•°æ®è½¬æ¢å®Œæˆï¼Œé•¿åº¦:', audioData.length)
      console.log('å‰10ä¸ªå­—èŠ‚:', Array.from(audioData.slice(0, 10)))
      // å°†éŸ³é¢‘æ•°æ®æ·»åŠ åˆ°é˜Ÿåˆ—å¹¶æ’­æ”¾
      audioQueue.value.push(audioData)
      processAudioQueue()
    } else {
      console.warn('æ”¶åˆ°ç©ºçš„éŸ³é¢‘åå…­è¿›åˆ¶å­—ç¬¦ä¸²')
    }
    
  } catch (error) {
    console.error('éŸ³é¢‘æ•°æ®å¤„ç†å¤±è´¥:', error)
  }
}

// å¼€å§‹å½•éŸ³
const startRecording = async () => {
  if (!audioStream) return
  
  try {
    mediaRecorder = new MediaRecorder(audioStream, {
      mimeType: 'audio/webm;codecs=opus'
    })
    
    const chunks: Blob[] = []
    
    mediaRecorder.ondataavailable = (event) => {
      if (event.data.size > 0) {
        chunks.push(event.data)
      }
    }
    
    mediaRecorder.onstop = async () => {
      const blob = new Blob(chunks, { type: 'audio/webm' })
      const duration = Date.now() - recordingStartTime
      
      // åªå¤„ç†è¶…è¿‡æœ€å°æ—¶é•¿çš„å½•éŸ³
      if (duration >= MIN_RECORDING_DURATION) {
        try {
          currentStatus.value = 'æ­£åœ¨è½¬æ¢è¯­éŸ³...'
          
          // å‘é€åˆ°é™ªä¼´æ¨¡å¼APIè¿›è¡Œå¤„ç†
        await sendRecordingToCompanion(blob)
        } catch (error) {
          console.error('é™ªä¼´æ¨¡å¼å¤„ç†å¤±è´¥:', error)
          currentStatus.value = 'è¯­éŸ³å¤„ç†å¤±è´¥ï¼Œè¯·é‡è¯•'
          setTimeout(() => {
            currentStatus.value = ''
          }, 3000)
        }
      } else {
        currentStatus.value = 'å½•éŸ³æ—¶é—´å¤ªçŸ­ï¼Œå·²ä¸¢å¼ƒ'
        setTimeout(() => {
          currentStatus.value = ''
        }, 2000)
      }
    }
    
    recordingStartTime = Date.now()
    mediaRecorder.start()
    isRecording.value = true
    isCurrentlyRecording = true
    currentStatus.value = 'æ­£åœ¨å½•éŸ³...'
    
    // å¼€å§‹ç›‘å¬éŸ³é¢‘
    monitorAudioLevel()
    
  } catch (error) {
    console.error('å½•éŸ³å¤±è´¥:', error)
    currentStatus.value = 'å½•éŸ³å¤±è´¥'
  }
}

// ä»ç›‘å¬æ¨¡å¼å¼€å§‹å½•éŸ³
const startRecordingFromListening = async () => {
  if (isCurrentlyRecording) return
  
  // åœæ­¢å½“å‰AIè¾“å‡ºï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
  if (isProcessing.value) {
    // è¿™é‡Œå¯ä»¥æ·»åŠ åœæ­¢AIè¾“å‡ºçš„é€»è¾‘
    console.log('æ£€æµ‹åˆ°ç”¨æˆ·è¯´è¯ï¼Œä¸­æ–­AIè¾“å‡º')
  }
  
  await startRecording()
}

// åœæ­¢å½•éŸ³
const stopRecording = () => {
  if (mediaRecorder && mediaRecorder.state === 'recording') {
    mediaRecorder.stop()
  }
  
  isRecording.value = false
  isCurrentlyRecording = false
  
  if (silenceTimeout) {
    clearTimeout(silenceTimeout)
    silenceTimeout = null
  }
  
  // å¦‚æœè¿˜åœ¨ç›‘å¬æ¨¡å¼ï¼Œç»§ç»­ç›‘æ§éŸ³é¢‘ï¼Œå¦åˆ™åœæ­¢
  if (isListening.value) {
    // ç»§ç»­ç›‘å¬ï¼Œä¸åœæ­¢åŠ¨ç”»å¸§
    console.log('å½•éŸ³ç»“æŸï¼Œç»§ç»­ç›‘å¬æ¨¡å¼')
  } else {
    if (animationFrame) {
      cancelAnimationFrame(animationFrame)
      animationFrame = null
    }
    audioLevel.value = 0
  }
}

// å¼€å§‹/åœæ­¢ç›‘å¬
const toggleListening = async () => {
  if (isListening.value) {
    stopListening()
  } else {
    await startListening()
  }
}

// å¼€å§‹ç›‘å¬
const startListening = async () => {
  try {
    console.log('å¼€å§‹å¯åŠ¨ç›‘å¬æ¨¡å¼...')
    if (!audioStream) {
      console.log('éŸ³é¢‘æµä¸å­˜åœ¨ï¼Œå¼€å§‹åˆå§‹åŒ–éŸ³é¢‘...')
      await initializeAudio()
    }
    
    isListening.value = true
    currentStatus.value = 'æ­£åœ¨ç›‘å¬éº¦å…‹é£...'
    console.log('ç›‘å¬çŠ¶æ€å·²è®¾ç½®ï¼Œå¼€å§‹éŸ³é¢‘ç›‘æ§')
    monitorAudioLevel()
    
  } catch (error) {
    console.error('å¯åŠ¨ç›‘å¬å¤±è´¥:', error)
    currentStatus.value = 'å¯åŠ¨ç›‘å¬å¤±è´¥'
  }
}

// åœæ­¢ç›‘å¬
const stopListening = () => {
  isListening.value = false
  
  if (animationFrame) {
    cancelAnimationFrame(animationFrame)
    animationFrame = null
  }
  
  audioLevel.value = 0
  currentStatus.value = ''
}





// æ ¼å¼åŒ–æ—¶é—´
const formatTime = (date: Date): string => {
  return date.toLocaleTimeString('zh-CN', {
    hour: '2-digit',
    minute: '2-digit',
    second: '2-digit'
  })
}

// æ ¼å¼åŒ–æ—¶é•¿
const formatDuration = (duration: number): string => {
  const seconds = Math.floor(duration / 1000)
  const minutes = Math.floor(seconds / 60)
  const remainingSeconds = seconds % 60
  
  if (minutes > 0) {
    return `${minutes}:${remainingSeconds.toString().padStart(2, '0')}`
  }
  return `${remainingSeconds}ç§’`
}

// æ¸…ç†èµ„æº
const cleanup = () => {
  stopRecording()
  stopListening()
  
  if (audioStream) {
    audioStream.getTracks().forEach(track => track.stop())
    audioStream = null
  }
  
  if (audioContext.value) {
    audioContext.value.close()
    audioContext.value = null
  }
}

// ç»„ä»¶æŒ‚è½½æ—¶åˆå§‹åŒ–
onMounted(() => {
  console.log('é™ªä¼´æ¨¡å¼ç»„ä»¶å·²æŒ‚è½½')
})

// ç»„ä»¶å¸è½½æ—¶æ¸…ç†
onUnmounted(() => {
  cleanup()
})
</script>

<style scoped>
.accompanying-mode {
  padding: 20px;
  max-width: 800px;
  margin: 0 auto;
  min-height: 100vh;
}

.header {
  text-align: center;
  margin-bottom: 30px;
  margin-left: 70px; /* ä¸å½•éŸ³æ§ä»¶å·¦è¾¹è·ä¿æŒä¸€è‡´ */
  margin-right: 20px; /* ä¸å½•éŸ³æ§ä»¶å³è¾¹è·ä¿æŒä¸€è‡´ */
  padding: 45px;
  background: white;
  border-radius: 12px;
  box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
  display: flex;
  flex-direction: column;
  align-items: center;
}

.header h2 {
  margin: 0 0 15px 0;
  color: #333;
  font-size: 28px;
  display: block;
  width: 100%;
  text-align: center;
}

.header hr {
  margin: 15px 0;
  border: none;
  border-top: 1px solid #e9ecef;
  width: 100%;
  display: block;
}

.header p {
  margin: 15px 0 0 0;
  color: #666;
  font-size: 16px;
  display: block;
  width: 100%;
  text-align: center;
}

.content {
  display: flex;
  flex-direction: column;
  gap: 20px;
  padding-bottom: 120px; /* ä¸ºåº•éƒ¨å›ºå®šçš„å½•éŸ³ç»„ä»¶ç•™å‡ºç©ºé—´ */
}

.conversation-history {
  background: white;
  border-radius: 12px;
  padding: 20px;
  box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
  margin-left: 70px; /* ä¸å½•éŸ³æ§ä»¶å·¦è¾¹è·ä¿æŒä¸€è‡´ */
  margin-right: 20px; /* ä¸å½•éŸ³æ§ä»¶å³è¾¹è·ä¿æŒä¸€è‡´ */
}

.conversation-history h3 {
  margin: 0 0 15px 0;
  color: #333;
  font-size: 20px;
}

.messages {
  max-height: 400px;
  overflow-y: auto;
  display: flex;
  flex-direction: column;
  gap: 12px;
}

.message {
  padding: 12px 16px;
  border-radius: 8px;
  max-width: 80%;
}

.message.user {
  background: #007bff;
  color: white;
  align-self: flex-end;
  margin-left: auto;
}

.message.assistant {
  background: #e9ecef;
  color: #333;
  align-self: flex-start;
}

.message-content {
  margin-bottom: 4px;
  line-height: 1.4;
  white-space: pre-wrap;
  word-wrap: break-word;
}

.message-time {
  font-size: 12px;
  opacity: 0.7;
}

.status-display {
  background: #fff3cd;
  border: 1px solid #ffeaa7;
  border-radius: 8px;
  padding: 12px 16px;
  margin-left: 70px; /* ä¸å½•éŸ³æ§ä»¶å·¦è¾¹è·ä¿æŒä¸€è‡´ */
  margin-right: 20px; /* ä¸å½•éŸ³æ§ä»¶å³è¾¹è·ä¿æŒä¸€è‡´ */
  text-align: center;
}

.status-text {
  color: #856404;
  font-weight: 500;
}

.config-error {
  background: #f8d7da;
  border: 1px solid #f5c6cb;
  border-radius: 12px;
  padding: 20px;
  margin-bottom: 20px;
  margin-left: 70px; /* ä¸å½•éŸ³æ§ä»¶å·¦è¾¹è·ä¿æŒä¸€è‡´ */
  margin-right: 20px; /* ä¸å½•éŸ³æ§ä»¶å³è¾¹è·ä¿æŒä¸€è‡´ */
  color: #721c24;
}

.config-error h3 {
  margin: 0 0 15px 0;
  color: #721c24;
  font-size: 18px;
}

.config-error ul {
  margin: 10px 0;
  padding-left: 20px;
}

.config-error li {
  margin: 5px 0;
}

.config-help {
  margin-top: 15px;
  padding: 15px;
  background: rgba(255, 255, 255, 0.5);
  border-radius: 8px;
}

.config-help ol {
  margin: 10px 0;
  padding-left: 20px;
}

.config-help li {
  margin: 8px 0;
  line-height: 1.4;
}

.config-help a {
  color: #0056b3;
  text-decoration: none;
}

.config-help a:hover {
  text-decoration: underline;
}

.config-help code {
  background: #e9ecef;
  padding: 2px 6px;
  border-radius: 4px;
  font-family: 'Courier New', monospace;
  font-size: 14px;
}

.test-tool-section {
  margin-top: 20px;
  margin-left: 70px; /* ä¸å½•éŸ³æ§ä»¶å·¦è¾¹è·ä¿æŒä¸€è‡´ */
  margin-right: 20px; /* ä¸å½•éŸ³æ§ä»¶å³è¾¹è·ä¿æŒä¸€è‡´ */
  padding: 15px;
  background: rgba(255, 255, 255, 0.7);
  border-radius: 8px;
  border: 1px solid #dee2e6;
}

.toggle-test-button,
.quick-test-button {
  background: #17a2b8;
  color: white;
  border: none;
  padding: 10px 20px;
  border-radius: 6px;
  cursor: pointer;
  font-size: 14px;
  font-weight: 500;
  transition: background-color 0.2s;
  margin-top: 10px;
}

.toggle-test-button:hover,
.quick-test-button:hover {
  background: #138496;
}

.test-tool-container {
  margin-top: 20px;
  margin-left: 70px; /* ä¸å½•éŸ³æ§ä»¶å·¦è¾¹è·ä¿æŒä¸€è‡´ */
  margin-right: 20px; /* ä¸å½•éŸ³æ§ä»¶å³è¾¹è·ä¿æŒä¸€è‡´ */
  padding: 20px;
  background: #f8f9fa;
  border-radius: 8px;
  border: 1px solid #dee2e6;
}

.quick-test {
  margin-top: 20px;
  margin-left: 70px; /* ä¸å½•éŸ³æ§ä»¶å·¦è¾¹è·ä¿æŒä¸€è‡´ */
  margin-right: 20px; /* ä¸å½•éŸ³æ§ä»¶å³è¾¹è·ä¿æŒä¸€è‡´ */
  padding: 15px;
  background: #e9ecef;
  border-radius: 8px;
  text-align: center;
}

.voice-recorder {
  background: white;
  border-radius: 12px;
  padding: 20px;
  box-shadow: 0 -2px 8px rgba(0, 0, 0, 0.1);
  position: fixed;
  bottom: 20px; /* æ·»åŠ åº•éƒ¨é—´è· */
  left: 70px; /* é¿å…è¦†ç›–å¯¼èˆªæ ï¼Œå¹¶ç•™å‡ºè¾¹è· */
  right: 20px; /* ä¸å…¶ä»–æ§ä»¶å³è¾¹è·ä¿æŒä¸€è‡´ */
  z-index: 999; /* é™ä½å±‚çº§ï¼Œç¡®ä¿ä¸è¦†ç›–å¯¼èˆªæ  */
  border: 1px solid #e9ecef;
}

.recorder-controls {
  display: flex;
  justify-content: center;
  align-items: center;
  gap: 15px;
  margin-bottom: 15px;
  flex-wrap: wrap;
}

.chat-button {
  padding: 12px 24px;
  border: none;
  border-radius: 8px;
  background: #007bff;
  color: white;
  cursor: pointer;
  font-size: 16px;
  font-weight: 500;
  transition: all 0.3s ease;
  min-width: 120px;
}

.chat-button:hover:not(:disabled) {
  background: #0056b3;
  transform: translateY(-1px);
}

.chat-button:disabled {
  opacity: 0.6;
  cursor: not-allowed;
}

.chat-button.recording {
  background: #dc3545;
  animation: pulse 1.5s infinite;
}

.chat-button.connecting {
  background: #ffc107;
  color: #000;
}

.chat-button.active {
  background: #28a745;
  animation: listening-pulse 2s infinite;
}

.audio-level {
  margin-top: 15px;
  text-align: center;
}

.level-bar {
  width: 100%;
  height: 8px;
  background: #e9ecef;
  border-radius: 4px;
  overflow: hidden;
  margin-bottom: 8px;
}

.level-fill {
  height: 100%;
  background: linear-gradient(90deg, #28a745, #ffc107, #dc3545);
  transition: width 0.1s ease;
  border-radius: 4px;
}

.level-text {
  font-size: 14px;
  color: #666;
  font-weight: 500;
}



@keyframes pulse {
  0% {
    transform: scale(1);
    box-shadow: 0 0 0 0 rgba(220, 53, 69, 0.7);
  }
  50% {
    transform: scale(1.05);
    box-shadow: 0 0 0 10px rgba(220, 53, 69, 0);
  }
  100% {
    transform: scale(1);
    box-shadow: 0 0 0 0 rgba(220, 53, 69, 0);
  }
}

@keyframes listening-pulse {
  0% {
    box-shadow: 0 0 0 0 rgba(40, 167, 69, 0.7);
  }
  50% {
    box-shadow: 0 0 0 10px rgba(40, 167, 69, 0);
  }
  100% {
    box-shadow: 0 0 0 0 rgba(40, 167, 69, 0);
  }
}

/* å“åº”å¼è®¾è®¡ */
@media (max-width: 768px) {
  .accompanying-mode {
    padding: 15px;
  }
  
  /* ç§»åŠ¨ç«¯ç»Ÿä¸€è¾¹è·è®¾ç½® */
  .conversation-history,
  .config-error,
  .status-display,
  .test-tool-section,
  .test-tool-container,
  .quick-test,
  .header {
    margin-left: 10px; /* ç§»åŠ¨ç«¯å‡å°‘è¾¹è· */
    margin-right: 10px;
  }
  
  .voice-recorder {
    right: 10px;
    bottom: 10px;
  }
  
  .header {
    text-align: center;
    margin-bottom: 30px;
    padding: 45px;
    background: white;
    border-radius: 12px;
    box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
    display: flex;
    flex-direction: column;
    align-items: center;
  }

.header h2 {
  margin: 0 0 15px 0;
  color: #333;
  font-size: 28px;
  display: block;
  width: 100%;
  text-align: center;
}

.header hr {
  margin: 15px 0;
  border: none;
  border-top: 1px solid #e9ecef;
  width: 100%;
  display: block;
}

.header p {
  margin: 15px 0 0 0;
  color: #666;
  font-size: 16px;
  display: block;
  width: 100%;
  text-align: center;
}
  
  .message {
    max-width: 90%;
  }
  
  .recorder-controls {
    flex-direction: column;
    align-items: stretch;
  }
  
  .chat-button {
    width: 100%;
  }
}

/* æ»šåŠ¨æ¡æ ·å¼ */
.messages::-webkit-scrollbar {
  width: 6px;
}

.messages::-webkit-scrollbar-track {
  background: #f1f1f1;
  border-radius: 3px;
}

.messages::-webkit-scrollbar-thumb {
  background: #c1c1c1;
  border-radius: 3px;
}

.messages::-webkit-scrollbar-thumb:hover {
  background: #a8a8a8;
}
</style>